{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e30a4f5b",
   "metadata": {},
   "source": [
    "### Setting up working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "07634c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2383129b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/munishpatel/AI-Medical-Assistant'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c97771",
   "metadata": {},
   "source": [
    "### Loading and Extracting data from the pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d8c58ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8324c402",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the data from the source (pdf) documents\n",
    "def load_pdf_file(data):\n",
    "    loader = DirectoryLoader(data, glob = \"*.pdf\", loader_cls = PyPDFLoader)\n",
    "    #Here *.pdf means only loading pdf's\n",
    "    documents = loader.load()\n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2d15bd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf_file(data = 'Data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0910b642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d121f5",
   "metadata": {},
   "source": [
    "### Performing Chunking operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "95258f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into small text chunks\n",
    "def text_split(extracted_data):\n",
    "    test_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 20)\n",
    "    text_chunks = test_splitter.split_documents(extracted_data)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3337990a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the text chunks is: 40000\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_split(extracted_data)\n",
    "print(\"The length of the text chunks is:\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7f6f4369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9184fbe4",
   "metadata": {},
   "source": [
    "### Importing Embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c1978ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "def get_embedding_model():\n",
    "    embedding_model = HuggingFaceEmbeddings(model_name = 'sentence-transformers/all-MiniLM-L6-v2')\n",
    "    return embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "64c1b8ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import sentence_transformers python package. Please install it with `pip install sentence-transformers`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI-Medical-Assistant/.venv/lib/python3.13/site-packages/langchain_community/embeddings/huggingface.py:84\u001b[39m, in \u001b[36mHuggingFaceEmbeddings.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sentence_transformers'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[80]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m embedding_model = \u001b[43mget_embedding_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m query_result = embedding_model.embed_query(\u001b[33m\"\u001b[39m\u001b[33mHello world\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLength\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(query_result))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[77]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mget_embedding_model\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_embedding_model\u001b[39m():\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     embedding_model = \u001b[43mHuggingFaceEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msentence-transformers/all-MiniLM-L6-v2\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m embedding_model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI-Medical-Assistant/.venv/lib/python3.13/site-packages/langchain_core/_api/deprecation.py:223\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    221\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    222\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI-Medical-Assistant/.venv/lib/python3.13/site-packages/langchain_community/embeddings/huggingface.py:87\u001b[39m, in \u001b[36mHuggingFaceEmbeddings.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     88\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCould not import sentence_transformers python package. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     89\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease install it with `pip install sentence-transformers`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     90\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m     92\u001b[39m \u001b[38;5;28mself\u001b[39m.client = sentence_transformers.SentenceTransformer(\n\u001b[32m     93\u001b[39m     \u001b[38;5;28mself\u001b[39m.model_name, cache_folder=\u001b[38;5;28mself\u001b[39m.cache_folder, **\u001b[38;5;28mself\u001b[39m.model_kwargs\n\u001b[32m     94\u001b[39m )\n",
      "\u001b[31mImportError\u001b[39m: Could not import sentence_transformers python package. Please install it with `pip install sentence-transformers`."
     ]
    }
   ],
   "source": [
    "embedding_model = get_embedding_model()\n",
    "query_result = embedding_model.embed_query(\"Hello world\")\n",
    "print(\"Length\", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51204e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
